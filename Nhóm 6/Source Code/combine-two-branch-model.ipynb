{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7989628,"sourceType":"datasetVersion","datasetId":4703395},{"sourceId":8004037,"sourceType":"datasetVersion","datasetId":4713734},{"sourceId":8004616,"sourceType":"datasetVersion","datasetId":4714154},{"sourceId":169837626,"sourceType":"kernelVersion"},{"sourceId":169846414,"sourceType":"kernelVersion"}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport cv2\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\nfrom tensorflow.keras.utils import to_categorical\n\n# Function to read data from CSV file\ndef read_data(pathCSV):\n    filenames = []\n    labels = []\n    \n    df = pd.read_csv(pathCSV)\n    \n    for index, row in df.iterrows():\n        filename = row['filename']\n        class_name = row['class']\n        \n        filenames.append(filename)\n        labels.append(class_name)\n        \n    return filenames, labels\n\n# Directories for train, valid, test data\ntrain_data_dir = '/kaggle/input/learntools/train/'\nvalidation_data_dir = '/kaggle/input/learntools/valid/'\ntest_data_dir = '/kaggle/input/learntools/test/'\n\n# Read data from train, valid, and test sets\ntrain_filenames, train_labels = read_data(os.path.join(train_data_dir, \"_annotations.csv\"))\ntest_filenames, test_labels = read_data(os.path.join(test_data_dir, \"_annotations.csv\"))\nvalidation_filenames, validation_labels = read_data(os.path.join(validation_data_dir, \"_annotations.csv\"))\n\n\n# Xử lý dữ liệu hình ảnh từ tập train\ntrain_images = []\ntrain_labels_list = []\nfor filename, label in zip(train_filenames, train_labels):\n    image = cv2.imread(os.path.join(train_data_dir, filename))\n    image = cv2.resize(image, (224, 224))  # Resize hình ảnh về kích thước 224x224\n    train_images.append(image)\n    train_labels_list.append(label)\n\ntrain_images = np.array(train_images) / 255.0  # Chuẩn hóa giá trị pixel về khoảng [0, 1]\ntrain_labels = pd.get_dummies(train_labels_list)  # Chuyển đổi nhãn sang one-hot encoding\n\n# Xử lý dữ liệu hình ảnh từ tập valid\nvalid_images = []\nvalid_labels_list = []\nfor filename, label in zip(validation_filenames, validation_labels):\n    image = cv2.imread(os.path.join(validation_data_dir, filename))\n    image = cv2.resize(image, (224, 224))  # Resize hình ảnh về kích thước 224x224\n    valid_images.append(image)\n    valid_labels_list.append(label)\n\nvalid_images = np.array(valid_images) / 255.0  # Chuẩn hóa giá trị pixel về khoảng [0, 1]\nvalid_labels = pd.get_dummies(valid_labels_list)  # Chuyển đổi nhãn sang one-hot encoding\n\n# Xử lý dữ liệu hình ảnh từ tập test\ntest_images = []\ntest_labels_list = []\nfor filename, label in zip(test_filenames, test_labels):\n    image = cv2.imread(os.path.join(test_data_dir, filename))\n    image = cv2.resize(image, (224, 224))  # Resize hình ảnh về kích thước 224x224\n    test_images.append(image)\n    test_labels_list.append(label)\n\ntest_images = np.array(test_images) / 255.0  # Chuẩn hóa giá trị pixel về khoảng [0, 1]\ntest_labels = pd.get_dummies(test_labels_list)  # Chuyển đổi nhãn sang one-hot encoding","metadata":{"execution":{"iopub.status.busy":"2024-04-02T09:20:38.532154Z","iopub.execute_input":"2024-04-02T09:20:38.532464Z","iopub.status.idle":"2024-04-02T09:21:05.296651Z","shell.execute_reply.started":"2024-04-02T09:20:38.532438Z","shell.execute_reply":"2024-04-02T09:21:05.295584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import các thư viện cần thiết\nimport os\nimport pandas as pd\nimport cv2\nimport numpy as np\n\n# Đọc dữ liệu từ các tệp CSV\ntest_df = pd.read_csv(\"/kaggle/input/learntools/test/_annotations.csv\")\ntrain_df = pd.read_csv(\"/kaggle/input/learntools/train/_annotations.csv\")\nvalid_df = pd.read_csv(\"/kaggle/input/learntools/valid/_annotations.csv\")\n\n# Hàm đọc ảnh và xử lý bounding box\ndef process_data(dataframe, data_dir):\n    images = []\n    labels = []\n    for index, row in dataframe.iterrows():\n        filename = row['filename']\n        image_path = os.path.join(data_dir, filename)\n        image = cv2.imread(image_path)  # Đọc ảnh\n        if image is not None:\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Chuyển đổi màu sắc từ BGR sang RGB\n            images.append(image)\n            \n            # Chuẩn hóa bounding box\n            xmin = row['xmin']\n            ymin = row['ymin']\n            xmax = row['xmax']\n            ymax = row['ymax']\n            width = row['width']  # Chiều rộng ảnh\n            height = row['height']  # Chiều cao ảnh\n            # Chuẩn hóa tọa độ bounding box\n            xmin_norm = xmin / width\n            ymin_norm = ymin / height\n            xmax_norm = xmax / width\n            ymax_norm = ymax / height\n            \n            labels.append([xmin_norm, ymin_norm, xmax_norm, ymax_norm])\n    \n    return np.array(images), np.array(labels)\n\n# Xử lý dữ liệu cho tập train, validation và test\ntrain_images_vgg16, train_labels_vgg16 = process_data(train_df, \"/kaggle/input/learntools/train/\")\nvalid_images_vgg16, valid_labels_vgg16 = process_data(valid_df, \"/kaggle/input/learntools/valid/\")\ntest_images_vgg16, test_labels_vgg16 = process_data(test_df, \"/kaggle/input/learntools/test/\")","metadata":{"execution":{"iopub.status.busy":"2024-04-02T09:21:05.297948Z","iopub.execute_input":"2024-04-02T09:21:05.298282Z","iopub.status.idle":"2024-04-02T09:21:14.538018Z","shell.execute_reply.started":"2024-04-02T09:21:05.298254Z","shell.execute_reply":"2024-04-02T09:21:14.536896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\n\n# Đường dẫn tới file model trên Kaggle\nmodel_path = \"/kaggle/input/models-classification/classification_CNN_model.h5\"\n\n# Load model từ file\ncnn_model = load_model(model_path)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T09:21:14.541405Z","iopub.execute_input":"2024-04-02T09:21:14.541742Z","iopub.status.idle":"2024-04-02T09:21:15.440529Z","shell.execute_reply.started":"2024-04-02T09:21:14.541715Z","shell.execute_reply":"2024-04-02T09:21:15.439606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Đánh giá mô hình trên tập test\ntest_loss_improved_cnn, test_accuracy_improved_cnn = cnn_model.evaluate(test_images, test_labels)\nprint(\"Test Loss:\", test_loss_improved_cnn)\nprint(\"Test Accuracy:\", test_accuracy_improved_cnn)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T09:21:15.441981Z","iopub.execute_input":"2024-04-02T09:21:15.442332Z","iopub.status.idle":"2024-04-02T09:21:22.660196Z","shell.execute_reply.started":"2024-04-02T09:21:15.442302Z","shell.execute_reply":"2024-04-02T09:21:22.659204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\n\n# Đường dẫn tới model trong thư mục chỉ đọc\nsource_model_path = \"/kaggle/input/bbox-best-model/vgg16_model_v2.keras\"\n\n# Đường dẫn đến thư mục có thể ghi được\ndestination_model_path = \"/kaggle/working/vgg16_model_v2.keras\"\n\n# Sao chép model từ thư mục chỉ đọc sang thư mục có thể ghi được\nshutil.copyfile(source_model_path, destination_model_path)\n\n# Load model từ thư mục có thể ghi được\nvgg16_model = load_model(destination_model_path)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-02T09:21:22.661487Z","iopub.execute_input":"2024-04-02T09:21:22.662104Z","iopub.status.idle":"2024-04-02T09:22:04.265325Z","shell.execute_reply.started":"2024-04-02T09:21:22.66207Z","shell.execute_reply":"2024-04-02T09:22:04.264284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Đánh giá mô hình trên tập test\ntest_loss_vgg16, test_accuracy_vgg16 = vgg16_model.evaluate(test_images_vgg16, test_labels_vgg16)\nprint(\"Test Loss:\", test_loss_vgg16)\nprint(\"Test Accuracy:\", test_accuracy_vgg16)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T09:22:04.266713Z","iopub.execute_input":"2024-04-02T09:22:04.267041Z","iopub.status.idle":"2024-04-02T09:22:45.764135Z","shell.execute_reply.started":"2024-04-02T09:22:04.267014Z","shell.execute_reply":"2024-04-02T09:22:45.762867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, concatenate, Dense\n\n# Tạo input cho mỗi mô hình\ncnn_input = Input(shape=(224, 224, 3))\nvgg16_input = Input(shape=(224, 224, 3))\n\n# Lấy output từ mô hình CNN\ncnn_output = cnn_model(cnn_input)\n\n# Lấy output từ mô hình VGG16\nvgg16_output = vgg16_model(vgg16_input)\n\n# Kết hợp outputs từ cả hai mô hình\ncombined_output = concatenate([cnn_output, vgg16_output])\n\n# Thêm các lớp fully connected và output\ncombined_output = Dense(512, activation='relu')(combined_output)\ncombined_output = Dense(5, activation='softmax')(combined_output)  # Số lớp phân loại\n\n# Tạo mô hình đa nhánh\ncombined_model = Model(inputs=[cnn_input, vgg16_input], outputs=combined_output)\n\n# Compile mô hình\ncombined_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Hiển thị tóm tắt của mô hình\ncombined_model.summary()\n\n# Huấn luyện mô hình\nhistory = combined_model.fit([train_images, train_images_vgg16], train_labels, epochs=10, batch_size=32, validation_data=([valid_images, valid_images_vgg16], valid_labels))\n\n# Đánh giá mô hình trên tập test\ntest_loss, test_accuracy = combined_model.evaluate([test_images, test_images_vgg16], test_labels)\nprint(\"Test Loss:\", test_loss)\nprint(\"Test Accuracy:\", test_accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-02T09:22:45.765385Z","iopub.execute_input":"2024-04-02T09:22:45.765752Z","iopub.status.idle":"2024-04-02T09:30:53.686232Z","shell.execute_reply.started":"2024-04-02T09:22:45.765723Z","shell.execute_reply":"2024-04-02T09:30:53.685165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Biểu đồ loss và accuracy\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-02T09:30:53.687756Z","iopub.execute_input":"2024-04-02T09:30:53.688167Z","iopub.status.idle":"2024-04-02T09:30:54.319283Z","shell.execute_reply.started":"2024-04-02T09:30:53.688119Z","shell.execute_reply":"2024-04-02T09:30:54.318354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, concatenate, Dense, Conv2D, MaxPooling2D, Flatten\n\n# Tạo input cho mỗi mô hình\ncnn_input = Input(shape=(224, 224, 3))\nvgg16_input = Input(shape=(224, 224, 3))\n\n# Tạo mô hình CNN\ncnn_output = Conv2D(32, (3, 3), activation='relu')(cnn_input)\ncnn_output = MaxPooling2D((2, 2))(cnn_output)\ncnn_output = Conv2D(64, (3, 3), activation='relu')(cnn_output)\ncnn_output = MaxPooling2D((2, 2))(cnn_output)\ncnn_output = Conv2D(128, (3, 3), activation='relu')(cnn_output)\ncnn_output = MaxPooling2D((2, 2))(cnn_output)\ncnn_output = Flatten()(cnn_output)\n\n# Tạo mô hình VGG16\nvgg16_output = vgg16_model(vgg16_input)\n\n# Kết hợp outputs từ cả hai mô hình\ncombined_output = concatenate([cnn_output, vgg16_output])\n\n# Thêm các lớp fully connected và output\ncombined_output = Dense(512, activation='relu')(combined_output)\ncombined_output = Dense(5, activation='softmax')(combined_output)  # Số lớp phân loại\n\n# Tạo mô hình đa nhánh\ncombined_model = Model(inputs=[cnn_input, vgg16_input], outputs=combined_output)\n\n# Compile mô hình\ncombined_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Hiển thị tóm tắt của mô hình\ncombined_model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-04-02T09:30:54.330786Z","iopub.execute_input":"2024-04-02T09:30:54.33109Z","iopub.status.idle":"2024-04-02T09:30:54.415991Z","shell.execute_reply.started":"2024-04-02T09:30:54.331063Z","shell.execute_reply":"2024-04-02T09:30:54.415069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Huấn luyện mô hình\nhistory = combined_model.fit([train_images, train_images_vgg16], train_labels, epochs=50, batch_size=32,\n                             validation_data=([valid_images, valid_images_vgg16], valid_labels))\n\n# Đánh giá mô hình trên tập test\ntest_loss, test_accuracy = combined_model.evaluate([test_images, test_images_vgg16], test_labels)\nprint(\"Test Loss:\", test_loss)\nprint(\"Test Accuracy:\", test_accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T09:30:54.417077Z","iopub.execute_input":"2024-04-02T09:30:54.417398Z","iopub.status.idle":"2024-04-02T10:00:15.081404Z","shell.execute_reply.started":"2024-04-02T09:30:54.41737Z","shell.execute_reply":"2024-04-02T10:00:15.08047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lưu mô hình vào file HDF5\ncombined_model.save(\"/kaggle/working/combined_model.keras\")","metadata":{"execution":{"iopub.status.busy":"2024-04-02T10:24:28.622833Z","iopub.execute_input":"2024-04-02T10:24:28.623649Z","iopub.status.idle":"2024-04-02T10:24:41.425276Z","shell.execute_reply.started":"2024-04-02T10:24:28.623603Z","shell.execute_reply":"2024-04-02T10:24:41.423931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\n\n# Hàm để hiển thị ảnh với bounding box và nhãn\ndef visualize_image(image, bbox, label, predicted_labels):\n    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n    if len(bbox.shape) == 1:  # Nếu chỉ có một bounding box\n        bbox = np.expand_dims(bbox, axis=0)  # Mở rộng kích thước của bbox\n    for i in range(len(bbox)):\n        xmin, ymin, xmax, ymax = bbox[i] * [image.shape[1], image.shape[0], image.shape[1], image.shape[0]]\n        xmin, ymin, xmax, ymax = int(xmin), int(ymin), int(xmax), int(ymax)\n        cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n        \n        # Hiển thị predicted labels trong bounding box\n        text = f\"{predicted_labels[i]}\"\n        cv2.putText(image, text, (xmin + 20, ymin + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n        \n    plt.imshow(image)\n    plt.axis('off')\n    plt.show()\n\n    \n# Lấy ảnh từ tập test\nimage_index = 9  # Chọn ảnh khác từ tập test\nimage_path = os.path.join(test_data_dir, test_filenames[image_index])\nimage = cv2.imread(image_path)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n# Đưa ảnh vào mô hình để dự đoán\npredicted_labels = combined_model.predict([test_images[image_index:image_index+1], test_images_vgg16[image_index:image_index+1]])\n\n# Lấy nhãn của đối tượng\nlabels = ['calculator', 'compa', 'pen', 'pencil', 'ruler']\npredicted_label_indices = np.argmax(predicted_labels, axis=1)\npredicted_label_names = [labels[i] for i in predicted_label_indices]\n\n# Lấy bounding box từ output của mô hình VGG16\nbbox = test_labels_vgg16[image_index]\n\n# Hiển thị ảnh với bounding box và nhãn\nvisualize_image(image, bbox, labels, predicted_label_names)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-02T10:00:15.082839Z","iopub.execute_input":"2024-04-02T10:00:15.083225Z","iopub.status.idle":"2024-04-02T10:00:19.821119Z","shell.execute_reply.started":"2024-04-02T10:00:15.083193Z","shell.execute_reply":"2024-04-02T10:00:19.819406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport cv2\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\nfrom tensorflow.keras.utils import to_categorical\n\n# Function to read data from CSV file\ndef read_data(pathCSV):\n    filenames = []\n    labels = []\n    \n    df = pd.read_csv(pathCSV)\n    \n    for index, row in df.iterrows():\n        filename = row['filename']\n        class_name = row['class']\n        \n        filenames.append(filename)\n        labels.append(class_name)\n        \n    return filenames, labels\n\ntest_data_dir = '/kaggle/input/nh-thc-t'\n\n# Xử lý dữ liệu hình ảnh từ tập test\ntest_images = []\ntest_labels_list = []\nfor filename, label in zip(test_filenames, test_labels):\n    image = cv2.imread(os.path.join(test_data_dir, filename))\n    image = cv2.resize(image, (224, 224))  # Resize hình ảnh về kích thước 224x224\n    test_images.append(image)\n    test_labels_list.append(label)\n\ntest_images = np.array(test_images) / 255.0  # Chuẩn hóa giá trị pixel về khoảng [0, 1]\n","metadata":{"execution":{"iopub.status.busy":"2024-04-02T10:02:00.295829Z","iopub.execute_input":"2024-04-02T10:02:00.296661Z","iopub.status.idle":"2024-04-02T10:02:01.203599Z","shell.execute_reply.started":"2024-04-02T10:02:00.296609Z","shell.execute_reply":"2024-04-02T10:02:01.202288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\nimport os\nimport numpy as np\n\ntest_data_dir = '/kaggle/input/nh-thc-t'\n\n# Load ảnh từ thư mục test_data_dir\ntest_filenames = os.listdir(test_data_dir)\ntest_images = []\n\nfor filename in test_filenames:\n    image_path = os.path.join(test_data_dir, filename)\n    image = cv2.imread(image_path)\n    image = cv2.resize(image, (224, 224))  # Resize ảnh về kích thước 224x224\n    image = image / 255.0  # Chuẩn hóa giá trị pixel về khoảng [0, 1]\n    test_images.append(image)\n\ntest_images = np.array(test_images)\n\n# Hàm để hiển thị ảnh với bounding box và nhãn\ndef visualize_image(image, bbox, label, predicted_labels):\n    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n    if len(bbox.shape) == 1:  # Nếu chỉ có một bounding box\n        bbox = np.expand_dims(bbox, axis=0)  # Mở rộng kích thước của bbox\n    for i in range(len(bbox)):\n        xmin, ymin, xmax, ymax = bbox[i] * [image.shape[1], image.shape[0], image.shape[1], image.shape[0]]\n        xmin, ymin, xmax, ymax = int(xmin), int(ymin), int(xmax), int(ymax)\n        cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n        \n        # Hiển thị predicted labels trong bounding box\n        text = f\"{predicted_labels[i]}\"\n        cv2.putText(image, text, (xmin + 20, ymin + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n        \n    plt.imshow(image)\n    plt.axis('off')\n    plt.show()\n\n# Lấy ảnh từ tập test\nimage_index = 2 # Chọn ảnh khác từ tập test\nimage_path = os.path.join(test_data_dir, test_filenames[image_index])\nimage = cv2.imread(image_path)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n# Đưa ảnh vào mô hình để dự đoán\npredicted_labels = combined_model.predict([test_images[image_index:image_index+1], test_images_vgg16[image_index:image_index+1]])\n\n# Lấy nhãn của đối tượng\nlabels = ['calculator', 'compa', 'pen', 'pencil', 'ruler']\npredicted_label_indices = np.argmax(predicted_labels, axis=1)\npredicted_label_names = [labels[i] for i in predicted_label_indices]\n\n# Lấy bounding box từ output của mô hình VGG16\nbbox = test_labels_vgg16[image_index]\n\n# Hiển thị ảnh với bounding box và nhãn\nvisualize_image(image, bbox, labels, predicted_label_names)\n3","metadata":{"execution":{"iopub.status.busy":"2024-04-02T10:02:03.934732Z","iopub.execute_input":"2024-04-02T10:02:03.935221Z","iopub.status.idle":"2024-04-02T10:02:04.770092Z","shell.execute_reply.started":"2024-04-02T10:02:03.935187Z","shell.execute_reply":"2024-04-02T10:02:04.769049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\nimport os\nimport numpy as np\n\n# Hàm để hiển thị ảnh với bounding box và nhãn\ndef visualize_image(image, bbox, label, predicted_labels):\n    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n    if len(bbox.shape) == 1:  # Nếu chỉ có một bounding box\n        bbox = np.expand_dims(bbox, axis=0)  # Mở rộng kích thước của bbox\n    for i in range(len(bbox)):\n        xmin, ymin, xmax, ymax = bbox[i] * [image.shape[1], image.shape[0], image.shape[1], image.shape[0]]\n        xmin, ymin, xmax, ymax = int(xmin), int(ymin), int(xmax), int(ymax)\n        cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n        \n        # Hiển thị predicted labels trong bounding box\n        text = f\"{predicted_labels[i]}\"\n        cv2.putText(image, text, (xmin + 20, ymin + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n        \n    plt.imshow(image)\n    plt.axis('off')\n    plt.show()\n\n# Lấy bounding box từ output của mô hình kết hợp\ncombined_output = combined_model.predict([np.expand_dims(new_image, axis=0), np.expand_dims(new_image, axis=0)])\npredicted_bbox = combined_output[:, -4:]  # Giả sử bounding box là 4 phần tử cuối cùng của output\n\n# Lấy ảnh từ đường dẫn hoặc bất kỳ nguồn nào khác\nimage_path = '/kaggle/input/nh-thc-t/pngtree-ballpoint-pen-photography-image_889170.jpg'\nimage = cv2.imread(image_path)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n# Hiển thị ảnh với bounding box và nhãn\nvisualize_image(image, predicted_bbox, labels, predicted_label_names)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-02T10:02:12.181902Z","iopub.execute_input":"2024-04-02T10:02:12.182284Z","iopub.status.idle":"2024-04-02T10:02:12.244458Z","shell.execute_reply.started":"2024-04-02T10:02:12.182244Z","shell.execute_reply":"2024-04-02T10:02:12.243283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}